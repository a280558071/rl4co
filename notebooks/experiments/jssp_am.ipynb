{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b005250-e17a-4e34-81ad-62fd26942d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0185840f-e92c-456c-a6c3-26c4c3eeecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.models.nn.attention import MultiHeadCrossAttention, MultiHeadAttention\n",
    "from rl4co.models.zoo.matnet.encoder import MixedScoresSDPA\n",
    "from rl4co.envs.scheduling.jssp import JSSPEnv\n",
    "from rl4co.models.nn.ops import Normalization\n",
    "from rl4co.models.zoo.common.decoder_only.policy import DecoderOnlyPolicy\n",
    "from rl4co.models.nn.graph.gcn import GCNEncoder\n",
    "from rl4co.models.nn.graph.graphCNN import GraphCNN\n",
    "from rl4co.models.nn.ops import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ede4d4a-001c-41a1-b09c-f1287213a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn_block = MultiHeadAttention(128, 8)\n",
    "cross_attn_block = MultiHeadCrossAttention(128, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d848703-78a0-4d32-a1c4-d48368909cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = JSSPEnv(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6b9c2f-8155-4799-8b88-5b803ce38dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env._reset(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b39525-9d46-46de-91bb-82511e38664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSSPInitEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, linear_bias=False):\n",
    "        super(JSSPInitEmbedding, self).__init__()\n",
    "\n",
    "        self.init_job_embed = nn.Linear(3, embedding_dim, linear_bias)\n",
    "        self.init_ma_embed = nn.Linear(1, embedding_dim, linear_bias)\n",
    "        self.pos_encoder = None\n",
    "\n",
    "    def forward(self, td: TensorDict):\n",
    "        bs = td.batch_size\n",
    "        durations = td[\"durations\"].reshape(*bs, -1) / 1000\n",
    "        lower_bounds = td[\"lower_bounds\"].reshape(*bs, -1) / 1000\n",
    "        finished_mark = td[\"finished_mark\"].reshape(*bs, -1)\n",
    "        job_feat = torch.stack((durations, lower_bounds, finished_mark), dim=-1)\n",
    "        job_emb = self.init_job_embed(job_feat)\n",
    "\n",
    "        ma_max_end = td[\"end_times\"].gather(2, td[\"machines\"]).max(1).values\n",
    "        ma_max_end = ma_max_end.reshape(*bs, -1, 1) / 1000\n",
    "        ma_emb = self.init_ma_embed(ma_max_end)\n",
    "\n",
    "        return job_emb, ma_emb\n",
    "\n",
    "\n",
    "class JSSPInitEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, linear_bias=False):\n",
    "        super(JSSPInitEmbedding, self).__init__()\n",
    "\n",
    "        self.init_job_embed = nn.Linear(4, embedding_dim, linear_bias)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim)\n",
    "\n",
    "    def forward(self, td: TensorDict):\n",
    "        bs, jobs, ops = td[\"durations\"].shape\n",
    "        total_ops = jobs * ops\n",
    "        \n",
    "        durations = td[\"durations\"].reshape(bs, -1) / 1000\n",
    "        start_times = td[\"start_times\"].reshape(bs, -1) / 1000\n",
    "        lower_bounds = td[\"lower_bounds\"].reshape(bs, -1) / 1000\n",
    "        finished_mark = td[\"finished_mark\"].reshape(bs, -1)\n",
    "        job_feat = torch.stack((start_times, durations, lower_bounds, finished_mark), dim=-1)\n",
    "        job_emb = self.init_job_embed(job_feat)\n",
    "\n",
    "        seq_pos = torch.arange(ops).repeat(jobs)[None].expand(bs, -1)\n",
    "        job_emb = self.pos_encoder(job_emb, seq_pos)\n",
    "\n",
    "        return job_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c9672d-2995-4871-9196-ef9a9c131135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op_ma_map = F.one_hot(td[\"machines\"].argsort(-1).reshape(*td.batch_size, -1), env.num_machines).to(torch.float32)\n",
    "# ma_emb = op_ma_map.transpose(-2, -1).bmm(job_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0e7f904-21cf-4a3e-9555-6a9aa693d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding_dim=128, \n",
    "        num_heads=8, \n",
    "        num_scores=1,\n",
    "        feed_forward_hidden=256,\n",
    "        normalization=\"batch\",\n",
    "    ):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        ms = MixedScoresSDPA(num_heads, num_scores=num_scores)\n",
    "        self.cross_attn_block = MultiHeadCrossAttention(\n",
    "            embedding_dim, num_heads, sdpa_fn=ms\n",
    "        )\n",
    "        self.F_a = nn.ModuleDict(\n",
    "            {\n",
    "                \"norm1\": Normalization(embedding_dim, normalization),\n",
    "                \"ffn\": nn.Sequential(\n",
    "                    nn.Linear(embedding_dim, feed_forward_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(feed_forward_hidden, embedding_dim),\n",
    "                ),\n",
    "                \"norm2\": Normalization(embedding_dim, normalization),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, x, dmat=None, mask=None):\n",
    "        x_out = self.cross_attn_block(x, x, cross_attn_mask=mask, dmat=dmat)\n",
    "        x_emb_out = self.F_a[\"norm1\"](x + x_out)\n",
    "        x_emb_out = self.F_a[\"norm2\"](x_emb_out + self.F_a[\"ffn\"](x_emb_out))\n",
    "        return x_emb_out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=128, num_heads=8, num_scores=1, num_l=3, linear_bias=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.init_emb = JSSPInitEmbedding(embedding_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderBlock(embedding_dim, num_heads, num_scores) for _ in range(num_l)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, td):\n",
    "        bs, num_jobs, num_ops = td[\"durations\"].shape\n",
    "        \n",
    "        init_emb = self.init_emb(td)\n",
    "        op_emb = init_emb.clone()\n",
    "        dmat = torch.stack(tuple(td.select(\"ops_on_same_ma_adj\", \"adjacency\").values()), dim=-1)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            op_emb = layer(op_emb, dmat=dmat)\n",
    "        \n",
    "        job_init_emb = init_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        job_emb = op_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        \n",
    "        return job_emb, job_init_emb\n",
    "\n",
    "      \n",
    "class Encoder(GCNEncoder):\n",
    "\n",
    "        \n",
    "    def __init__(self, embedding_dim, num_layers):\n",
    "    \n",
    "        def edge_idx_fn(td, *args, **kwargs):\n",
    "            return torch.permute(td[\"adjacency\"].nonzero(), (1,0))\n",
    "        \n",
    "        init_embedding = JSSPInitEmbedding(emb_dim)\n",
    "        \n",
    "        super().__init__(\"jssp\", embedding_dim, num_layers, init_embedding=init_embedding, edge_idx_fn=edge_idx_fn)\n",
    "\n",
    "    def forward(self, td):\n",
    "        bs, num_jobs, num_ops = td[\"durations\"].shape\n",
    "        op_emb, init_emb = super().forward(td)\n",
    "        job_init_emb = init_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        job_emb = op_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        \n",
    "        return job_emb, job_init_emb     \n",
    "\n",
    "\n",
    "class Encoder(GraphCNN):\n",
    "    def __init__(self, embedding_dim, num_layers):\n",
    "        super().__init__(\"jssp\", embedding_dim, num_layers)\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, td):\n",
    "        bs, num_jobs, num_ops = td[\"durations\"].shape\n",
    "        op_emb, init_emb = super().forward(td)\n",
    "        job_init_emb = init_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        job_emb = op_emb.gather(1, td[\"next_op\"][...,None].expand(bs, num_jobs, self.embedding_dim))\n",
    "        \n",
    "        return job_emb, job_init_emb    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e07cf05-ade8-4c04-a072-46fd3331b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128\n",
    "layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0211422b-bd8a-443e-b43a-dd8d620e1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(emb_dim, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "805961bd-815e-47a9-9f00-bdfe6c238227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = Encoder(num_scores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8acd1c2c-21f8-4df1-a63c-0a760296ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb, _ = enc(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "793959c6-8a17-4909-800f-8516a0e1322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88209756-f1c0-4364-83b8-30f79a2a7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jssp_policy = DecoderOnlyPolicy(\n",
    "    env_name=env, embedding_dim=emb_dim, feature_extractor=enc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b9760ba-e268-43a2-9b50-f1ab4eaf63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.models.rl import PPO, REINFORCE\n",
    "class L2DReinforce(REINFORCE):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        policy,\n",
    "        baseline = \"rollout\",\n",
    "        policy_kwargs={},\n",
    "        baseline_kwargs={},\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if policy is None:\n",
    "            policy = DecoderOnlyPolicy(env.name, **policy_kwargs)\n",
    "\n",
    "        super().__init__(env, policy, baseline, baseline_kwargs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bfc2512c-cfb6-4c4e-9c7e-49e2c06eb334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luttmann/opt/miniconda3/envs/rl4co/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/Users/luttmann/opt/miniconda3/envs/rl4co/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "model = L2DReinforce(\n",
    "    env, \n",
    "    jssp_policy,\n",
    "    batch_size = 50,\n",
    "    val_batch_size = None,\n",
    "    test_batch_size = None,\n",
    "    train_data_size = 10000,\n",
    "    val_data_size = 1000,\n",
    "    test_data_size = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8543da0-5186-4c32-a3b0-90afdd0abcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luttmann/opt/miniconda3/envs/rl4co/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:551: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from rl4co.utils.trainer import RL4COTrainer\n",
    "\n",
    "trainer = RL4COTrainer(\n",
    "    max_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52ca9bf3-e07e-4eb3-bb7e-761e52538d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "\n",
      "  | Name     | Type              | Params\n",
      "-----------------------------------------------\n",
      "0 | env      | JSSPEnv           | 0     \n",
      "1 | policy   | DecoderOnlyPolicy | 83.6 K\n",
      "2 | baseline | WarmupBaseline    | 83.6 K\n",
      "-----------------------------------------------\n",
      "167 K     Trainable params\n",
      "0         Non-trainable params\n",
      "167 K     Total params\n",
      "0.669     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luttmann/opt/miniconda3/envs/rl4co/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/luttmann/opt/miniconda3/envs/rl4co/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9736f1617e44e896d8e785651b0ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                     | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa51f5-e436-42e0-a4ee-8725ea547821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
